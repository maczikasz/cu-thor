# Things to cover

## API

### High level Library API

The library API should provide the following methods to the clients:

* Initialize an executor instance with the following settings
  * Limits for resources
    

* Execute a command with the supplied arguments, that returns a pointer to a `Command` object that can be later used to manipulate the underlying process

### GRPC API definition

The GRPC API defines the following methods:

* ExecuteCommand: Starts a command with limited resources in its own namespace with the supplied arguments
* StopExecution : Stop a certain execution, issues a SIGTERM than after a configured amount of seconds issues a SIGKILL
* ListExecutions: List all the executions the connected client has rights to
* GetExecution: Gets metadata about a certain execution defined by an execution ID
* GetOutStream: Get a stream of standard output (stdout & stderr) of a certain execution

To read about the exact details of the API you can look at [the proto file](api.proto). The server will return UUIDs as ExecutionId that will be then used to later identify a certain execution. The reason for not using PID as an ExecutionId is because PIDs could be reused which could lead to unexpected behaviour from the application

### Streaming data

In order to be able to stream and also send the full output of the processes we need to store the output of this in memory for simplicty. See [Tradeoffs](#tradeoffs) section for information about why this solution should not be used in production  

## Security

### Cipher suite

In order to have the latest and strongest transport encryption TLS 1.3 should be utilized. The cipher suite TLS_AES_128_GCM_SHA256 is the mandatory cipher suite for TLS 1.3, and it provides sufficiently strong encryption there for it will be used by the server
The decision to ultimately use TLS 1.3 is due to the fact that the client and the server controlled by the same entity, therefore it's easy to enforce the usage of the latest version

### Authentication

### mTLS

For the mTLS the following certificates will be generated by a generate-certs shell script to enable easy testing of the application (see the Tradeoff section for more details):

* A root CA certificate to sign client and server CSR-s 
* A x509 certificate for the server signed by the root CA
* Two x509 certificates one for each of two clients, that could be used to connect to the applicaiton

The root CA will use a private key that's 4096 bits and the client and server certs will use private keys with 2048 bits

### Authorization

To keep things simple, the following statement should hold for every process started on the server:

`Only clients authenticated with the client certs having the same CN can get any information about, or interact with a certain process`

## Process execution

### Resource control

To control resource allocation linux control groups (cgroups) can be utilized

For the required CPU, Memory, and DiskIO limits a new cgroup could be created per process using the cpu, memory and blkio controllers

### Isolation

To implement isolation of namespaces for PID, Mount and Networks unix namespaces will be used

In order to be able to set up proper isolation there is need to run some initialization process before the app executes in the new namespace.

## Client

The client CLI will have a two top level commands:

`start` and `execution`

The `start` command will send a command to be started to the server, along with the arguments passed to it

```
Usage: args start [--command COMMAND] [ARGS [ARGS ...]]

Positional arguments:
  ARGS                   these arguments will be supplied to the executed command

Options:
  --command COMMAND      the command to be executed on the server

```

The example of `cu-thor start --command head /dev/random` will result in executing the command `head` with the argument `/dev/random`
Similarly the command `cu-thor start --command head -- -n10 /dev/random` will execute the command `head` with the arguments `-n10` and `/dev/random`

The `execution` will have a `list` subcommand that will return the current executions that this client has rights to interact with

The `execution` subcommand will also provide all functions to manipulate an existing execution on the server like, `status`, `stop`, `output`, to use these subcommands a `--id` parameter must be supplied with the id of the execution

```
Usage: args execution <command> [<args>]
  --help, -h             display this help and exit

Commands:
  list                   shows information about the currently available executions
  stop                   stops an execution
  status                 returns the information about a certain execution
  output                 streams the output of a certain execution
```



# Tradeoffs

## Log storage

The in memory log storage has two serious drawbacks. 
* A single offending process can fill the memory of the server with output
* The executions metadata needs to be kept in memory after the execution have finished, a recycling of the executions should be implemented

One mitigation step would be to store the output of the single processes in a predefined directory. This would allow the server to rely on this directory to return the output. The downside of this is that the app needs to implement a `tail -f` type function to stream the data the client

## Cert generation

The current cert generation with the script is not a good way to easily provision the required certs to new client. Also the company will probably wish to use it's own CA to sign an intermediate CA that will sign the CSR for the server and the clients. This should be automated depending on the setup of how the clients actually use the application

## Persistent storage

Execution metadata and output live only as far as the server keeps it in memory. After a server crash/restart all previous executions are lost. This could be acceptable, but most likely some form of persistent storage should be introduced
